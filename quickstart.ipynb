{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973a85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd93476e",
   "metadata": {},
   "source": [
    "## Define tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "732b4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply `a` and `b`.\n",
    "\n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds `a` and `b`.\n",
    "\n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide `a` and `b`.\n",
    "\n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f94a1",
   "metadata": {},
   "source": [
    "## Define model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b158c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ddc9a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10977b770>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10a15c2f0>, root_client=<openai.OpenAI object at 0x109778ec0>, root_async_client=<openai.AsyncOpenAI object at 0x10a15c050>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), kwargs={'tools': [{'type': 'function', 'function': {'name': 'add', 'description': 'Adds `a` and `b`.\\n\\nArgs:\\n    a: First int\\n    b: Second int', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiply `a` and `b`.\\n\\nArgs:\\n    a: First int\\n    b: Second int', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'divide', 'description': 'Divide `a` and `b`.\\n\\nArgs:\\n    a: First int\\n    b: Second int', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [add, multiply, divide]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "model_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fb314",
   "metadata": {},
   "source": [
    "## Define State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2a8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "from langchain.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    llm_calls: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0365478b",
   "metadata": {},
   "source": [
    "## Define model node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47dfb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "def llm_call(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return MessagesState(\n",
    "        messages=[\n",
    "            model_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ],\n",
    "        llm_calls=state.get(\"llm_calls\", 0) + 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9561f753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 4},\n",
       "  'id': 'call_OhM5rso2oTbT72V9pFthvRpi',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = model_with_tools.invoke(\n",
    "    [HumanMessage(content=\"Hello! What is 3 multiplied by 4?\")]\n",
    ")\n",
    "ms.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94c420",
   "metadata": {},
   "source": [
    "## Define tool node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f097322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = ms.tool_calls[0]\n",
    "tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1344a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import ToolMessage\n",
    "\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064deed7",
   "metadata": {},
   "source": [
    "## Define end logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81226a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ed42d",
   "metadata": {},
   "source": [
    "## Build and compile the agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a26dd802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "# nodes\n",
    "agent_builder.set_entry_point(\"llm_call\")\n",
    "agent_builder.add_conditional_edges(\"llm_call\", should_continue, [\"tool_node\", END])\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "\n",
    "# Compile agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "# Show graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d8541",
   "metadata": {},
   "source": [
    "## Invoke\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa68939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Multiply that by 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_kiMAij7tujfXJv6DNZyZxcbZ)\n",
      " Call ID: call_kiMAij7tujfXJv6DNZyZxcbZ\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_fLHGN99SkROndptQ2pTOjYV9)\n",
      " Call ID: call_fLHGN99SkROndptQ2pTOjYV9\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 4, and then multiplying by 2 is 14.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"Add 3 and 4. Multiply that by 2\")]\n",
    "messages = agent.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36f419dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Multiply that by 2. List the tool calls\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_RCunPJ6mGO08MK9riUMw79dY)\n",
      " Call ID: call_RCunPJ6mGO08MK9riUMw79dY\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "  multiply (call_EjApnkWXKMPyiqo0Mqo5Qnlw)\n",
      " Call ID: call_EjApnkWXKMPyiqo0Mqo5Qnlw\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The tool calls made were:\n",
      "\n",
      "1. `functions.add` with parameters `a: 3` and `b: 4`, which resulted in 7.\n",
      "2. `functions.multiply` with parameters `a: 7` and `b: 2`, which resulted in 14.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"Add 3 and 4. Multiply that by 2. List the tool calls\")]\n",
    "messages = agent.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd4e4439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Multiply that by 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_kiMAij7tujfXJv6DNZyZxcbZ)\n",
      " Call ID: call_kiMAij7tujfXJv6DNZyZxcbZ\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_fLHGN99SkROndptQ2pTOjYV9)\n",
      " Call ID: call_fLHGN99SkROndptQ2pTOjYV9\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 4, and then multiplying by 2 is 14.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Explain\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure! Let's break down the steps:\n",
      "\n",
      "1. **Addition**: We start by adding the numbers 3 and 4 together. \n",
      "   \\[\n",
      "   3 + 4 = 7\n",
      "   \\]\n",
      "\n",
      "2. **Multiplication**: Next, we take the result from the addition, which is 7, and multiply it by 2.\n",
      "   \\[\n",
      "   7 \\times 2 = 14\n",
      "   \\]\n",
      "\n",
      "So, the final result of the operation is 14.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "messages_explain = messages[\"messages\"] + [HumanMessage(content=\"Explain\")]\n",
    "messages_explain = agent.invoke({\"messages\": messages_explain})\n",
    "for m in messages_explain[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af31faef",
   "metadata": {},
   "source": [
    "### Use middlewares to log state at each step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaf921ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import after_model\n",
    "\n",
    "\n",
    "@after_model\n",
    "def log_state_after_model(state, runtime):\n",
    "    print()\n",
    "    print(\"---------------------------------------\")\n",
    "    print()\n",
    "    for m in state[\"messages\"]:\n",
    "        m.pretty_print()\n",
    "\n",
    "\n",
    "agent_with_logging = create_agent(\n",
    "    model=\"gpt-4o\", tools=tools, middleware=[log_state_after_model]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4876656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(agent_with_logging.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f121701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Also add 2 and 6. Multiply the first result by 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_OHrpNsTAReH1T7Uhu1NbZLTf)\n",
      " Call ID: call_OHrpNsTAReH1T7Uhu1NbZLTf\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "  add (call_189lpSBUzhqGS3MC1JJRmvHB)\n",
      " Call ID: call_189lpSBUzhqGS3MC1JJRmvHB\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 6\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Also add 2 and 6. Multiply the first result by 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_OHrpNsTAReH1T7Uhu1NbZLTf)\n",
      " Call ID: call_OHrpNsTAReH1T7Uhu1NbZLTf\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "  add (call_189lpSBUzhqGS3MC1JJRmvHB)\n",
      " Call ID: call_189lpSBUzhqGS3MC1JJRmvHB\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 6\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "8\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_t0dyy3e5fBqOeo2jZFAme566)\n",
      " Call ID: call_t0dyy3e5fBqOeo2jZFAme566\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Also add 2 and 6. Multiply the first result by 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_OHrpNsTAReH1T7Uhu1NbZLTf)\n",
      " Call ID: call_OHrpNsTAReH1T7Uhu1NbZLTf\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "  add (call_189lpSBUzhqGS3MC1JJRmvHB)\n",
      " Call ID: call_189lpSBUzhqGS3MC1JJRmvHB\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 6\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "8\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_t0dyy3e5fBqOeo2jZFAme566)\n",
      " Call ID: call_t0dyy3e5fBqOeo2jZFAme566\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 4 is 7. The result of adding 2 and 6 is 8. Multiplying the first result (7) by 2 gives 14.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Add 3 and 4. Also add 2 and 6. Multiply the first result by 2\"\n",
    "    )\n",
    "]\n",
    "messages = agent_with_logging.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1689c54",
   "metadata": {},
   "source": [
    "## Keep short memory between invocations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85d6e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent_with_short_memory = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=tools,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f50fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Add 3 and 4. Also add 2 and 6. Multiply the first result by 2\"\n",
    "    )\n",
    "]\n",
    "messages = agent_with_short_memory.invoke({\"messages\": messages}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d261a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = agent_with_short_memory.invoke(\n",
    "    {\"messages\": \"what did I say earlier?\"}, config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd2c2429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Also add 2 and 6. Multiply the first result by 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_M9Q3Xs6gelQuQO1Jfr68hmM5)\n",
      " Call ID: call_M9Q3Xs6gelQuQO1Jfr68hmM5\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "  add (call_vFisGu9h9BnPdRS3d9q4VSet)\n",
      " Call ID: call_vFisGu9h9BnPdRS3d9q4VSet\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 6\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "8\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_ZwapmicG768hYePhbMsKIM4p)\n",
      " Call ID: call_ZwapmicG768hYePhbMsKIM4p\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7, the sum of 2 and 6 is 8, and multiplying the first result by 2 gives 14.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what did I say earlier?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You asked me to add 3 and 4, also add 2 and 6, and then multiply the first result by 2.\n"
     ]
    }
   ],
   "source": [
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a7608c",
   "metadata": {},
   "source": [
    "## Use middlewares to trim messages history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c673b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import after_model, before_model\n",
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "\n",
    "\n",
    "@after_model\n",
    "def log_state_after_model(state, runtime):\n",
    "    print()\n",
    "    print(\"---------------------------------------\")\n",
    "    print()\n",
    "    for m in state[\"messages\"]:\n",
    "        m.pretty_print()\n",
    "\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state, runtime):\n",
    "    print(\"+++ Trimming messages: keep first and last 2 +++\")\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        new_messages = messages\n",
    "    else:\n",
    "        first_msg = messages[0]\n",
    "        recent_messages = messages[-2:]\n",
    "        new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES), *new_messages]}\n",
    "\n",
    "\n",
    "agent_with_trimmed_messages = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=tools,\n",
    "    middleware=[\n",
    "        log_state_after_model,\n",
    "        trim_messages,\n",
    "    ],\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bc34a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Trimming messages: keep first and last 2 +++\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Also add 2 and 6. Multiply the first result by 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_Tja1hj5dI4Z0RRdTtUZ96VEG)\n",
      " Call ID: call_Tja1hj5dI4Z0RRdTtUZ96VEG\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "  add (call_bfrbp3VR4G5O7UROIrrPhJzi)\n",
      " Call ID: call_bfrbp3VR4G5O7UROIrrPhJzi\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 6\n",
      "+++ Trimming messages: keep first and last 2 +++\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid parameter: messages with role 'tool' must be a response to a preceeding message with 'tool_calls'.\", 'type': 'invalid_request_error', 'param': 'messages.[1].role', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m messages = [\n\u001b[32m      2\u001b[39m     HumanMessage(\n\u001b[32m      3\u001b[39m         content=\u001b[33m\"\u001b[39m\u001b[33mAdd 3 and 4. Also add 2 and 6. Multiply the first result by 2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m     )\n\u001b[32m      5\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m messages = \u001b[43magent_with_trimmed_messages\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langgraph/pregel/main.py:3050\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3048\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3050\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3051\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3055\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3056\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3058\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3059\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3060\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3062\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3064\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3065\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langgraph/pregel/main.py:2633\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2631\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2632\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2633\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2640\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langchain/agents/factory.py:1073\u001b[39m, in \u001b[36mcreate_agent.<locals>.model_node\u001b[39m\u001b[34m(state, runtime)\u001b[39m\n\u001b[32m   1060\u001b[39m request = ModelRequest(\n\u001b[32m   1061\u001b[39m     model=model,\n\u001b[32m   1062\u001b[39m     tools=default_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1068\u001b[39m     runtime=runtime,\n\u001b[32m   1069\u001b[39m )\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wrap_model_call_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1072\u001b[39m     \u001b[38;5;66;03m# No handlers - execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m     response = \u001b[43m_execute_model_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# Call composed handler with base handler\u001b[39;00m\n\u001b[32m   1076\u001b[39m     response = wrap_model_call_handler(request, _execute_model_sync)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langchain/agents/factory.py:1046\u001b[39m, in \u001b[36mcreate_agent.<locals>._execute_model_sync\u001b[39m\u001b[34m(request)\u001b[39m\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request.system_prompt:\n\u001b[32m   1044\u001b[39m     messages = [SystemMessage(request.system_prompt), *messages]\n\u001b[32m-> \u001b[39m\u001b[32m1046\u001b[39m output = \u001b[43mmodel_\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[38;5;66;03m# Handle model output to get messages and structured_response\u001b[39;00m\n\u001b[32m   1049\u001b[39m handled_output = _handle_model_output(output, effective_response_format)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langchain_core/runnables/base.py:5534\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5527\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5528\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5529\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5532\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5533\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5534\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5535\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5536\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5537\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5538\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:382\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    375\u001b[39m     **kwargs: Any,\n\u001b[32m    376\u001b[39m ) -> AIMessage:\n\u001b[32m    377\u001b[39m     config = ensure_config(config)\n\u001b[32m    378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    380\u001b[39m         cast(\n\u001b[32m    381\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    392\u001b[39m         ).message,\n\u001b[32m    393\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1101\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1094\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1098\u001b[39m     **kwargs: Any,\n\u001b[32m   1099\u001b[39m ) -> LLMResult:\n\u001b[32m   1100\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:911\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    909\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    910\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m911\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m         )\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1205\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1203\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1204\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1205\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1209\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1299\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1298\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1299\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1302\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1303\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1304\u001b[39m ):\n\u001b[32m   1305\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1294\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1287\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1288\u001b[39m             response,\n\u001b[32m   1289\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1290\u001b[39m             metadata=generation_info,\n\u001b[32m   1291\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1292\u001b[39m         )\n\u001b[32m   1293\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1295\u001b[39m         response = raw_response.parse()\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1156\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1110\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1112\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1153\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1154\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1155\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/agentic/lib/python3.13/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid parameter: messages with role 'tool' must be a response to a preceeding message with 'tool_calls'.\", 'type': 'invalid_request_error', 'param': 'messages.[1].role', 'code': None}}",
      "During task with name 'model' and id '2cf6b640-4746-a86b-1184-32ebdc3ba915'"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Add 3 and 4. Also add 2 and 6. Multiply the first result by 2\"\n",
    "    )\n",
    "]\n",
    "messages = agent_with_trimmed_messages.invoke({\"messages\": messages}, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7255423d",
   "metadata": {},
   "source": [
    "## Use TODO middleware\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import TodoListMiddleware, after_model\n",
    "\n",
    "\n",
    "@after_model\n",
    "def log_state_after_model(state, runtime):\n",
    "    print()\n",
    "    print(\"---------------------------------------\")\n",
    "    print()\n",
    "    for m in state[\"messages\"]:\n",
    "        m.pretty_print()\n",
    "\n",
    "\n",
    "agent_with_todo = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=tools,\n",
    "    middleware=[\n",
    "        TodoListMiddleware(\n",
    "            system_prompt=\"Always create a todo list via write_todos before solving anything\"\n",
    "        ),\n",
    "        log_state_after_model,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Add 3 and 4. Also add 2 and 6. Multiply the first result by 2. Divide the result by 3. Add first and third operations. Subtract 5 from the final result.\"\n",
    "    )\n",
    "]\n",
    "result = agent_with_todo.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"todos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in result[\"messages\"]:\n",
    "    if getattr(m, \"tool_calls\", None):\n",
    "        print([tc[\"name\"] for tc in m.tool_calls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ae2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(agent_with_short_memory.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd9cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
